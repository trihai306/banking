#!/usr/bin/env python3
"""
Qwen3 Dataset Builder - Táº¡o Training Data theo Chuáº©n Qwen3

Script Python Ä‘á»ƒ xÃ¢y dá»±ng vÃ  chuáº©n bá»‹ dataset cho training Qwen3/Qwen3VL model.

Usage:
    python qwen3_dataset_builder.py --input data.csv --output dataset.json
    python qwen3_dataset_builder.py --input data.json --format qa --output dataset.jsonl
    python qwen3_dataset_builder.py --input data.jsonl --format jsonl --output dataset.json --split 0.2

Theo tÃ i liá»‡u: https://qwen.readthedocs.io/en/latest/
"""

import json
import os
import argparse
from typing import List, Dict, Any, Optional
from pathlib import Path
import pandas as pd
from datasets import Dataset, DatasetDict
from tqdm import tqdm


class Qwen3DatasetBuilder:
    """
    Dataset Builder cho Qwen3/Qwen3VL training
    Theo chuáº©n Qwen3: https://qwen.readthedocs.io/en/latest/
    
    Format chuáº©n Qwen3:
    {
        "messages": [
            {"role": "user", "content": [{"type": "text", "text": "..."}]},
            {"role": "assistant", "content": [{"type": "text", "text": "..."}]}
        ]
    }
    """
    
    def __init__(self, include_image: bool = False):
        """
        Args:
            include_image: Náº¿u True, há»— trá»£ image trong content (Qwen3VL)
        """
        self.include_image = include_image
        self.dataset = []
        self.stats = {
            "total_samples": 0,
            "total_conversations": 0,
            "total_turns": 0,
            "avg_turns_per_conv": 0,
            "total_tokens_estimate": 0,
        }
    
    def add_conversation(self, messages: List[Dict[str, Any]]) -> None:
        """ThÃªm má»™t conversation vÃ o dataset"""
        if not self._validate_messages(messages):
            raise ValueError("Messages khÃ´ng Ä‘Ãºng format Qwen3")
        
        self.dataset.append({"messages": messages})
        self._update_stats(messages)
    
    def add_simple_qa(self, question: str, answer: str, image_path: Optional[str] = None) -> None:
        """ThÃªm má»™t Q&A Ä‘Æ¡n giáº£n (1 turn conversation)"""
        user_content = []
        
        if image_path and self.include_image:
            user_content.append({"type": "image", "image": image_path})
        
        user_content.append({"type": "text", "text": question})
        
        messages = [
            {"role": "user", "content": user_content},
            {"role": "assistant", "content": [{"type": "text", "text": answer}]}
        ]
        
        self.add_conversation(messages)
    
    def add_multi_turn_conversation(self, turns: List[Dict[str, str]], image_path: Optional[str] = None) -> None:
        """ThÃªm multi-turn conversation"""
        messages = []
        
        for i, turn in enumerate(turns):
            if "user" not in turn or "assistant" not in turn:
                raise ValueError(f"Turn {i} pháº£i cÃ³ 'user' vÃ  'assistant'")
            
            user_content = []
            if image_path and self.include_image and i == 0:
                user_content.append({"type": "image", "image": image_path})
            user_content.append({"type": "text", "text": turn["user"]})
            messages.append({"role": "user", "content": user_content})
            
            messages.append({
                "role": "assistant",
                "content": [{"type": "text", "text": turn["assistant"]}]
            })
        
        self.add_conversation(messages)
    
    def load_from_json(self, file_path: str, format_type: str = "auto") -> None:
        """Load dataset tá»« JSON file"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if format_type == "auto":
            format_type = self._detect_format(data)
        
        if format_type == "qwen3":
            if isinstance(data, list):
                for item in data:
                    if "messages" in item:
                        self.add_conversation(item["messages"])
            elif isinstance(data, dict) and "messages" in data:
                self.add_conversation(data["messages"])
        elif format_type == "qa":
            for item in data:
                self.add_simple_qa(item.get("question", ""), item.get("answer", ""))
        elif format_type == "conversation":
            for item in data:
                if "turns" in item:
                    self.add_multi_turn_conversation(item["turns"])
        
        print(f"âœ… ÄÃ£ load {len(data) if isinstance(data, list) else 1} samples tá»« {file_path}")
    
    def load_from_csv(self, file_path: str, question_col: str = "question", answer_col: str = "answer") -> None:
        """Load dataset tá»« CSV file"""
        df = pd.read_csv(file_path)
        
        if question_col not in df.columns or answer_col not in df.columns:
            raise ValueError(f"CSV pháº£i cÃ³ columns: {question_col}, {answer_col}")
        
        for _, row in tqdm(df.iterrows(), total=len(df), desc="Loading CSV"):
            question = str(row[question_col]).strip()
            answer = str(row[answer_col]).strip()
            
            if question and answer:
                self.add_simple_qa(question, answer)
        
        print(f"âœ… ÄÃ£ load {len(df)} samples tá»« {file_path}")
    
    def load_from_jsonl(self, file_path: str) -> None:
        """Load tá»« JSONL file (má»—i dÃ²ng má»™t JSON conversation)"""
        count = 0
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                
                try:
                    data = json.loads(line)
                    if "messages" in data:
                        self.add_conversation(data["messages"])
                        count += 1
                except json.JSONDecodeError as e:
                    print(f"âš ï¸  Lá»—i á»Ÿ dÃ²ng {line_num}: {e}")
        
        print(f"âœ… ÄÃ£ load {count} samples tá»« {file_path}")
    
    def _validate_messages(self, messages: List[Dict[str, Any]]) -> bool:
        """Validate messages format theo chuáº©n Qwen3"""
        if not isinstance(messages, list) or len(messages) == 0:
            return False
        
        for msg in messages:
            if not isinstance(msg, dict):
                return False
            
            if "role" not in msg or "content" not in msg:
                return False
            
            if msg["role"] not in ["user", "assistant", "system"]:
                return False
            
            if not isinstance(msg["content"], list):
                return False
            
            for content_item in msg["content"]:
                if not isinstance(content_item, dict):
                    return False
                if "type" not in content_item:
                    return False
                if content_item["type"] == "text":
                    if "text" not in content_item:
                        return False
                elif content_item["type"] == "image":
                    if "image" not in content_item:
                        return False
                    if not self.include_image:
                        return False
                else:
                    return False
        
        return True
    
    def _detect_format(self, data: Any) -> str:
        """Tá»± Ä‘á»™ng detect format cá»§a data"""
        if isinstance(data, list) and len(data) > 0:
            first_item = data[0]
            if isinstance(first_item, dict):
                if "messages" in first_item:
                    return "qwen3"
                elif "question" in first_item and "answer" in first_item:
                    return "qa"
                elif "turns" in first_item:
                    return "conversation"
        elif isinstance(data, dict):
            if "messages" in data:
                return "qwen3"
        
        return "qa"
    
    def _update_stats(self, messages: List[Dict[str, Any]]) -> None:
        """Cáº­p nháº­t thá»‘ng kÃª"""
        self.stats["total_conversations"] += 1
        self.stats["total_turns"] += len([m for m in messages if m["role"] == "user"])
        
        total_chars = 0
        for msg in messages:
            for content in msg.get("content", []):
                if content.get("type") == "text":
                    total_chars += len(content.get("text", ""))
        self.stats["total_tokens_estimate"] += total_chars // 4
        
        self.stats["total_samples"] = len(self.dataset)
        if self.stats["total_conversations"] > 0:
            self.stats["avg_turns_per_conv"] = self.stats["total_turns"] / self.stats["total_conversations"]
    
    def get_stats(self) -> Dict[str, Any]:
        """Láº¥y thá»‘ng kÃª dataset"""
        return self.stats.copy()
    
    def preview(self, n: int = 3) -> None:
        """Preview n samples Ä‘áº§u tiÃªn"""
        print(f"\nğŸ“Š Preview {min(n, len(self.dataset))} samples Ä‘áº§u tiÃªn:\n")
        for i, sample in enumerate(self.dataset[:n], 1):
            print(f"--- Sample {i} ---")
            print(json.dumps(sample, ensure_ascii=False, indent=2))
            print()
    
    def to_huggingface_dataset(self) -> Dataset:
        """Convert sang Hugging Face Dataset"""
        return Dataset.from_list(self.dataset)
    
    def save_to_json(self, file_path: str, indent: int = 2) -> None:
        """LÆ°u dataset ra JSON file"""
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(self.dataset, f, ensure_ascii=False, indent=indent)
        print(f"âœ… ÄÃ£ lÆ°u {len(self.dataset)} samples vÃ o {file_path}")
    
    def save_to_jsonl(self, file_path: str) -> None:
        """LÆ°u dataset ra JSONL file"""
        with open(file_path, 'w', encoding='utf-8') as f:
            for item in self.dataset:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        print(f"âœ… ÄÃ£ lÆ°u {len(self.dataset)} samples vÃ o {file_path}")
    
    def split_train_test(self, test_ratio: float = 0.1, shuffle: bool = True, seed: int = 42) -> DatasetDict:
        """Chia dataset thÃ nh train vÃ  test"""
        dataset = self.to_huggingface_dataset()
        
        if shuffle:
            dataset = dataset.shuffle(seed=seed)
        
        split_dataset = dataset.train_test_split(test_size=test_ratio, seed=seed)
        return split_dataset


def main():
    parser = argparse.ArgumentParser(
        description="Qwen3 Dataset Builder - Táº¡o Training Data theo Chuáº©n Qwen3",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
VÃ­ dá»¥ sá»­ dá»¥ng:
  # Load tá»« CSV vÃ  export ra JSON
  python qwen3_dataset_builder.py --input data.csv --output dataset.json
  
  # Load tá»« JSON vá»›i format Q&A
  python qwen3_dataset_builder.py --input data.json --format qa --output dataset.jsonl
  
  # Load tá»« JSONL vÃ  chia train/test
  python qwen3_dataset_builder.py --input data.jsonl --format jsonl --output dataset.json --split 0.2
  
  # Preview dataset
  python qwen3_dataset_builder.py --input data.json --preview 5
        """
    )
    
    parser.add_argument(
        "--input", "-i",
        type=str,
        required=True,
        help="ÄÆ°á»ng dáº«n file input (CSV, JSON, hoáº·c JSONL)"
    )
    
    parser.add_argument(
        "--output", "-o",
        type=str,
        default=None,
        help="ÄÆ°á»ng dáº«n file output (JSON hoáº·c JSONL). Náº¿u khÃ´ng chá»‰ Ä‘á»‹nh, chá»‰ preview"
    )
    
    parser.add_argument(
        "--format", "-f",
        type=str,
        default="auto",
        choices=["auto", "qwen3", "qa", "conversation", "csv", "jsonl"],
        help="Format cá»§a file input (auto: tá»± Ä‘á»™ng detect)"
    )
    
    parser.add_argument(
        "--question-col",
        type=str,
        default="question",
        help="TÃªn cá»™t chá»©a cÃ¢u há»i (cho CSV)"
    )
    
    parser.add_argument(
        "--answer-col",
        type=str,
        default="answer",
        help="TÃªn cá»™t chá»©a cÃ¢u tráº£ lá»i (cho CSV)"
    )
    
    parser.add_argument(
        "--split",
        type=float,
        default=None,
        help="Tá»· lá»‡ test set (0.0-1.0). Náº¿u chá»‰ Ä‘á»‹nh, sáº½ táº¡o train/test split"
    )
    
    parser.add_argument(
        "--preview", "-p",
        type=int,
        default=0,
        help="Sá»‘ samples Ä‘á»ƒ preview (0 = khÃ´ng preview)"
    )
    
    parser.add_argument(
        "--include-image",
        action="store_true",
        help="Há»— trá»£ image trong content (cho Qwen3VL)"
    )
    
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="Random seed cho train/test split"
    )
    
    args = parser.parse_args()
    
    # Kiá»ƒm tra file input
    if not os.path.exists(args.input):
        print(f"âŒ File khÃ´ng tá»“n táº¡i: {args.input}")
        return
    
    # Táº¡o builder
    builder = Qwen3DatasetBuilder(include_image=args.include_image)
    
    # Load data
    print(f"ğŸ“‚ Äang load data tá»« {args.input}...")
    input_ext = Path(args.input).suffix.lower()
    
    if args.format == "jsonl" or input_ext == ".jsonl":
        builder.load_from_jsonl(args.input)
    elif args.format == "csv" or input_ext == ".csv":
        builder.load_from_csv(args.input, question_col=args.question_col, answer_col=args.answer_col)
    else:
        builder.load_from_json(args.input, format_type=args.format)
    
    # Preview
    if args.preview > 0:
        builder.preview(args.preview)
    
    # Thá»‘ng kÃª
    stats = builder.get_stats()
    print("\n" + "="*50)
    print("ğŸ“Š THá»NG KÃŠ DATASET")
    print("="*50)
    for key, value in stats.items():
        print(f"{key}: {value}")
    
    # Export
    if args.output:
        output_ext = Path(args.output).suffix.lower()
        
        if args.split is not None:
            # Chia train/test
            print(f"\nğŸ”„ Äang chia dataset (test ratio: {args.split})...")
            split_dataset = builder.split_train_test(test_ratio=args.split, shuffle=True, seed=args.seed)
            
            print(f"âœ… Train set: {len(split_dataset['train'])} samples")
            print(f"âœ… Test set: {len(split_dataset['test'])} samples")
            
            # LÆ°u train/test
            train_path = str(Path(args.output).with_suffix('.train.jsonl'))
            test_path = str(Path(args.output).with_suffix('.test.jsonl'))
            
            # Convert train/test vá» list vÃ  lÆ°u
            train_data = [{"messages": item["messages"]} for item in split_dataset['train']]
            test_data = [{"messages": item["messages"]} for item in split_dataset['test']]
            
            with open(train_path, 'w', encoding='utf-8') as f:
                for item in train_data:
                    f.write(json.dumps(item, ensure_ascii=False) + '\n')
            
            with open(test_path, 'w', encoding='utf-8') as f:
                for item in test_data:
                    f.write(json.dumps(item, ensure_ascii=False) + '\n')
            
            print(f"âœ… ÄÃ£ lÆ°u train set vÃ o {train_path}")
            print(f"âœ… ÄÃ£ lÆ°u test set vÃ o {test_path}")
        else:
            # LÆ°u toÃ n bá»™ dataset
            if output_ext == ".jsonl":
                builder.save_to_jsonl(args.output)
            else:
                builder.save_to_json(args.output)
    
    print("\nâœ… HoÃ n thÃ nh!")


if __name__ == "__main__":
    main()

