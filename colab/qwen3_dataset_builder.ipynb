{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen3 Dataset Builder - Táº¡o Training Data theo Chuáº©n Qwen3\n",
    "\n",
    "Notebook nÃ y giÃºp xÃ¢y dá»±ng vÃ  chuáº©n bá»‹ dataset cho training Qwen3/Qwen3VL model.\n",
    "\n",
    "## TÃ­nh nÄƒng:\n",
    "- ğŸ“ Táº¡o dataset tá»« nhiá»u nguá»“n (JSON, CSV, conversation logs)\n",
    "- âœ… Validate format theo chuáº©n Qwen3\n",
    "- ğŸ”„ Convert cÃ¡c format khÃ¡c nhau sang format Qwen3\n",
    "- ğŸ“Š Thá»‘ng kÃª vÃ  preview dataset\n",
    "- ğŸ’¾ Export dataset (JSON, Hugging Face format)\n",
    "- ğŸ¯ Há»— trá»£ cáº£ text-only vÃ  multimodal (text + image)\n",
    "\n",
    "## Format chuáº©n Qwen3:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"messages\": [\n",
    "    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]},\n",
    "    {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Theo tÃ i liá»‡u: https://qwen.readthedocs.io/en/latest/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CÃ i Ä‘áº·t Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t\n",
    "# Theo tÃ i liá»‡u Qwen: https://qwen.readthedocs.io/en/latest/\n",
    "%pip install -q \"transformers>=4.41.0,<5.0.0\"\n",
    "%pip install -q datasets\n",
    "%pip install -q pandas\n",
    "%pip install -q pillow  # Cho image processing (náº¿u dÃ¹ng Qwen3VL)\n",
    "%pip install -q tqdm\n",
    "\n",
    "print(\"âœ… Dependencies Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "print(\"âœ… Libraries Ä‘Ã£ Ä‘Æ°á»£c import!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Qwen3DatasetBuilder Class\n",
    "\n",
    "Class chÃ­nh Ä‘á»ƒ xÃ¢y dá»±ng dataset theo chuáº©n Qwen3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qwen3DatasetBuilder:\n",
    "    \"\"\"\n",
    "    Dataset Builder cho Qwen3/Qwen3VL training\n",
    "    Theo chuáº©n Qwen3: https://qwen.readthedocs.io/en/latest/\n",
    "    \n",
    "    Format chuáº©n Qwen3:\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]},\n",
    "            {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    Hoáº·c vá»›i image (Qwen3VL):\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image\", \"image\": \"path_or_url\"},\n",
    "                {\"type\": \"text\", \"text\": \"...\"}\n",
    "            ]},\n",
    "            {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, include_image: bool = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            include_image: Náº¿u True, há»— trá»£ image trong content (Qwen3VL)\n",
    "        \"\"\"\n",
    "        self.include_image = include_image\n",
    "        self.dataset = []\n",
    "        self.stats = {\n",
    "            \"total_samples\": 0,\n",
    "            \"total_conversations\": 0,\n",
    "            \"total_turns\": 0,\n",
    "            \"avg_turns_per_conv\": 0,\n",
    "            \"total_tokens_estimate\": 0,\n",
    "        }\n",
    "    \n",
    "    def add_conversation(self, messages: List[Dict[str, Any]]) -> None:\n",
    "        \"\"\"\n",
    "        ThÃªm má»™t conversation vÃ o dataset\n",
    "        \n",
    "        Args:\n",
    "            messages: List of messages theo format Qwen3\n",
    "                [\n",
    "                    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]},\n",
    "                    {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]}\n",
    "                ]\n",
    "        \"\"\"\n",
    "        # Validate messages\n",
    "        if not self._validate_messages(messages):\n",
    "            raise ValueError(\"Messages khÃ´ng Ä‘Ãºng format Qwen3\")\n",
    "        \n",
    "        self.dataset.append({\"messages\": messages})\n",
    "        self._update_stats(messages)\n",
    "    \n",
    "    def add_simple_qa(self, question: str, answer: str, image_path: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        ThÃªm má»™t Q&A Ä‘Æ¡n giáº£n (1 turn conversation)\n",
    "        \n",
    "        Args:\n",
    "            question: CÃ¢u há»i cá»§a user\n",
    "            answer: CÃ¢u tráº£ lá»i cá»§a assistant\n",
    "            image_path: ÄÆ°á»ng dáº«n áº£nh (náº¿u cÃ³, cho Qwen3VL)\n",
    "        \"\"\"\n",
    "        user_content = []\n",
    "        \n",
    "        # ThÃªm image náº¿u cÃ³\n",
    "        if image_path and self.include_image:\n",
    "            user_content.append({\"type\": \"image\", \"image\": image_path})\n",
    "        \n",
    "        # ThÃªm text\n",
    "        user_content.append({\"type\": \"text\", \"text\": question})\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "            {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": answer}]}\n",
    "        ]\n",
    "        \n",
    "        self.add_conversation(messages)\n",
    "    \n",
    "    def add_multi_turn_conversation(self, turns: List[Dict[str, str]], image_path: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        ThÃªm multi-turn conversation\n",
    "        \n",
    "        Args:\n",
    "            turns: List of turns, má»—i turn lÃ  {\"user\": \"...\", \"assistant\": \"...\"}\n",
    "            image_path: ÄÆ°á»ng dáº«n áº£nh (náº¿u cÃ³, chá»‰ thÃªm vÃ o turn Ä‘áº§u tiÃªn)\n",
    "        \"\"\"\n",
    "        messages = []\n",
    "        \n",
    "        for i, turn in enumerate(turns):\n",
    "            if \"user\" not in turn or \"assistant\" not in turn:\n",
    "                raise ValueError(f\"Turn {i} pháº£i cÃ³ 'user' vÃ  'assistant'\")\n",
    "            \n",
    "            # User message\n",
    "            user_content = []\n",
    "            if image_path and self.include_image and i == 0:  # Chá»‰ thÃªm image vÃ o turn Ä‘áº§u\n",
    "                user_content.append({\"type\": \"image\", \"image\": image_path})\n",
    "            user_content.append({\"type\": \"text\", \"text\": turn[\"user\"]})\n",
    "            messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "            \n",
    "            # Assistant message\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": turn[\"assistant\"]}]\n",
    "            })\n",
    "        \n",
    "        self.add_conversation(messages)\n",
    "    \n",
    "    def load_from_json(self, file_path: str, format_type: str = \"auto\") -> None:\n",
    "        \"\"\"\n",
    "        Load dataset tá»« JSON file\n",
    "        \n",
    "        Args:\n",
    "            file_path: ÄÆ°á»ng dáº«n file JSON\n",
    "            format_type: Format cá»§a file (\"auto\", \"qwen3\", \"qa\", \"conversation\")\n",
    "        \"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if format_type == \"auto\":\n",
    "            format_type = self._detect_format(data)\n",
    "        \n",
    "        if format_type == \"qwen3\":\n",
    "            # Format Ä‘Ã£ Ä‘Ãºng Qwen3\n",
    "            if isinstance(data, list):\n",
    "                for item in data:\n",
    "                    if \"messages\" in item:\n",
    "                        self.add_conversation(item[\"messages\"])\n",
    "            elif isinstance(data, dict) and \"messages\" in data:\n",
    "                self.add_conversation(data[\"messages\"])\n",
    "        elif format_type == \"qa\":\n",
    "            # Format Q&A: [{\"question\": \"...\", \"answer\": \"...\"}]\n",
    "            for item in data:\n",
    "                self.add_simple_qa(item.get(\"question\", \"\"), item.get(\"answer\", \"\"))\n",
    "        elif format_type == \"conversation\":\n",
    "            # Format conversation: [{\"turns\": [{\"user\": \"...\", \"assistant\": \"...\"}]}]\n",
    "            for item in data:\n",
    "                if \"turns\" in item:\n",
    "                    self.add_multi_turn_conversation(item[\"turns\"])\n",
    "        \n",
    "        print(f\"âœ… ÄÃ£ load {len(data) if isinstance(data, list) else 1} samples tá»« {file_path}\")\n",
    "    \n",
    "    def load_from_csv(self, file_path: str, question_col: str = \"question\", answer_col: str = \"answer\") -> None:\n",
    "        \"\"\"\n",
    "        Load dataset tá»« CSV file\n",
    "        \n",
    "        Args:\n",
    "            file_path: ÄÆ°á»ng dáº«n file CSV\n",
    "            question_col: TÃªn cá»™t chá»©a cÃ¢u há»i\n",
    "            answer_col: TÃªn cá»™t chá»©a cÃ¢u tráº£ lá»i\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if question_col not in df.columns or answer_col not in df.columns:\n",
    "            raise ValueError(f\"CSV pháº£i cÃ³ columns: {question_col}, {answer_col}\")\n",
    "        \n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Loading CSV\"):\n",
    "            question = str(row[question_col]).strip()\n",
    "            answer = str(row[answer_col]).strip()\n",
    "            \n",
    "            if question and answer:\n",
    "                self.add_simple_qa(question, answer)\n",
    "        \n",
    "        print(f\"âœ… ÄÃ£ load {len(df)} samples tá»« {file_path}\")\n",
    "    \n",
    "    def load_from_conversation_logs(self, file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Load tá»« conversation logs (format: má»—i dÃ²ng lÃ  má»™t JSON conversation)\n",
    "        \n",
    "        Args:\n",
    "            file_path: ÄÆ°á»ng dáº«n file (JSONL format)\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    if \"messages\" in data:\n",
    "                        self.add_conversation(data[\"messages\"])\n",
    "                        count += 1\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"âš ï¸  Lá»—i á»Ÿ dÃ²ng {line_num}: {e}\")\n",
    "        \n",
    "        print(f\"âœ… ÄÃ£ load {count} samples tá»« {file_path}\")\n",
    "    \n",
    "    def _validate_messages(self, messages: List[Dict[str, Any]]) -> bool:\n",
    "        \"\"\"\n",
    "        Validate messages format theo chuáº©n Qwen3\n",
    "        \"\"\"\n",
    "        if not isinstance(messages, list) or len(messages) == 0:\n",
    "            return False\n",
    "        \n",
    "        for msg in messages:\n",
    "            if not isinstance(msg, dict):\n",
    "                return False\n",
    "            \n",
    "            if \"role\" not in msg or \"content\" not in msg:\n",
    "                return False\n",
    "            \n",
    "            if msg[\"role\"] not in [\"user\", \"assistant\", \"system\"]:\n",
    "                return False\n",
    "            \n",
    "            if not isinstance(msg[\"content\"], list):\n",
    "                return False\n",
    "            \n",
    "            for content_item in msg[\"content\"]:\n",
    "                if not isinstance(content_item, dict):\n",
    "                    return False\n",
    "                if \"type\" not in content_item:\n",
    "                    return False\n",
    "                if content_item[\"type\"] == \"text\":\n",
    "                    if \"text\" not in content_item:\n",
    "                        return False\n",
    "                elif content_item[\"type\"] == \"image\":\n",
    "                    if \"image\" not in content_item:\n",
    "                        return False\n",
    "                    if not self.include_image:\n",
    "                        return False  # KhÃ´ng há»— trá»£ image\n",
    "                else:\n",
    "                    return False  # Type khÃ´ng há»£p lá»‡\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _detect_format(self, data: Any) -> str:\n",
    "        \"\"\"\n",
    "        Tá»± Ä‘á»™ng detect format cá»§a data\n",
    "        \"\"\"\n",
    "        if isinstance(data, list) and len(data) > 0:\n",
    "            first_item = data[0]\n",
    "            if isinstance(first_item, dict):\n",
    "                if \"messages\" in first_item:\n",
    "                    return \"qwen3\"\n",
    "                elif \"question\" in first_item and \"answer\" in first_item:\n",
    "                    return \"qa\"\n",
    "                elif \"turns\" in first_item:\n",
    "                    return \"conversation\"\n",
    "        elif isinstance(data, dict):\n",
    "            if \"messages\" in data:\n",
    "                return \"qwen3\"\n",
    "        \n",
    "        return \"qa\"  # Default\n",
    "    \n",
    "    def _update_stats(self, messages: List[Dict[str, Any]]) -> None:\n",
    "        \"\"\"\n",
    "        Cáº­p nháº­t thá»‘ng kÃª\n",
    "        \"\"\"\n",
    "        self.stats[\"total_conversations\"] += 1\n",
    "        self.stats[\"total_turns\"] += len([m for m in messages if m[\"role\"] == \"user\"])\n",
    "        \n",
    "        # Estimate tokens (rough: ~4 chars per token)\n",
    "        total_chars = 0\n",
    "        for msg in messages:\n",
    "            for content in msg.get(\"content\", []):\n",
    "                if content.get(\"type\") == \"text\":\n",
    "                    total_chars += len(content.get(\"text\", \"\"))\n",
    "        self.stats[\"total_tokens_estimate\"] += total_chars // 4\n",
    "        \n",
    "        self.stats[\"total_samples\"] = len(self.dataset)\n",
    "        if self.stats[\"total_conversations\"] > 0:\n",
    "            self.stats[\"avg_turns_per_conv\"] = self.stats[\"total_turns\"] / self.stats[\"total_conversations\"]\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Láº¥y thá»‘ng kÃª dataset\n",
    "        \"\"\"\n",
    "        return self.stats.copy()\n",
    "    \n",
    "    def preview(self, n: int = 3) -> None:\n",
    "        \"\"\"\n",
    "        Preview n samples Ä‘áº§u tiÃªn\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸ“Š Preview {min(n, len(self.dataset))} samples Ä‘áº§u tiÃªn:\\n\")\n",
    "        for i, sample in enumerate(self.dataset[:n], 1):\n",
    "            print(f\"--- Sample {i} ---\")\n",
    "            print(json.dumps(sample, ensure_ascii=False, indent=2))\n",
    "            print()\n",
    "    \n",
    "    def to_huggingface_dataset(self) -> Dataset:\n",
    "        \"\"\"\n",
    "        Convert sang Hugging Face Dataset\n",
    "        \"\"\"\n",
    "        return Dataset.from_list(self.dataset)\n",
    "    \n",
    "    def save_to_json(self, file_path: str, indent: int = 2) -> None:\n",
    "        \"\"\"\n",
    "        LÆ°u dataset ra JSON file\n",
    "        \"\"\"\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.dataset, f, ensure_ascii=False, indent=indent)\n",
    "        print(f\"âœ… ÄÃ£ lÆ°u {len(self.dataset)} samples vÃ o {file_path}\")\n",
    "    \n",
    "    def save_to_jsonl(self, file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        LÆ°u dataset ra JSONL file (má»—i dÃ²ng má»™t JSON)\n",
    "        \"\"\"\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            for item in self.dataset:\n",
    "                f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "        print(f\"âœ… ÄÃ£ lÆ°u {len(self.dataset)} samples vÃ o {file_path}\")\n",
    "    \n",
    "    def split_train_test(self, test_ratio: float = 0.1, shuffle: bool = True, seed: int = 42) -> DatasetDict:\n",
    "        \"\"\"\n",
    "        Chia dataset thÃ nh train vÃ  test\n",
    "        \n",
    "        Args:\n",
    "            test_ratio: Tá»· lá»‡ test set (0.0 - 1.0)\n",
    "            shuffle: CÃ³ shuffle khÃ´ng\n",
    "            seed: Random seed\n",
    "        \"\"\"\n",
    "        dataset = self.to_huggingface_dataset()\n",
    "        \n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(seed=seed)\n",
    "        \n",
    "        split_dataset = dataset.train_test_split(test_size=test_ratio, seed=seed)\n",
    "        \n",
    "        return split_dataset\n",
    "\n",
    "print(\"âœ… Qwen3DatasetBuilder class Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. VÃ­ dá»¥ sá»­ dá»¥ng - Táº¡o Dataset tá»« Q&A Ä‘Æ¡n giáº£n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o builder (text-only, khÃ´ng cÃ³ image)\n",
    "builder = Qwen3DatasetBuilder(include_image=False)\n",
    "\n",
    "# ThÃªm má»™t sá»‘ Q&A máº«u vá» ngÃ¢n hÃ ng\n",
    "builder.add_simple_qa(\n",
    "    question=\"LÃ£i suáº¥t tiáº¿t kiá»‡m hiá»‡n táº¡i lÃ  bao nhiÃªu?\",\n",
    "    answer=\"LÃ£i suáº¥t tiáº¿t kiá»‡m hiá»‡n táº¡i dao Ä‘á»™ng tá»« 4.5% Ä‘áº¿n 6.5% tÃ¹y theo ká»³ háº¡n vÃ  loáº¡i sáº£n pháº©m. Báº¡n cÃ³ thá»ƒ liÃªn há»‡ chi nhÃ¡nh gáº§n nháº¥t Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.\"\n",
    ")\n",
    "\n",
    "builder.add_simple_qa(\n",
    "    question=\"LÃ m tháº¿ nÃ o Ä‘á»ƒ má»Ÿ tÃ i khoáº£n ngÃ¢n hÃ ng?\",\n",
    "    answer=\"Äá»ƒ má»Ÿ tÃ i khoáº£n ngÃ¢n hÃ ng, báº¡n cáº§n: 1) CMND/CCCD, 2) Äáº¿n chi nhÃ¡nh hoáº·c Ä‘Äƒng kÃ½ online, 3) Äiá»n form Ä‘Äƒng kÃ½, 4) Ná»™p phÃ­ má»Ÿ tÃ i khoáº£n (náº¿u cÃ³). Thá»i gian xá»­ lÃ½ thÆ°á»ng 1-2 ngÃ y lÃ m viá»‡c.\"\n",
    ")\n",
    "\n",
    "builder.add_simple_qa(\n",
    "    question=\"TÃ´i cÃ³ thá»ƒ vay tÃ­n cháº¥p vá»›i má»©c lÆ°Æ¡ng 10 triá»‡u khÃ´ng?\",\n",
    "    answer=\"Vá»›i má»©c lÆ°Æ¡ng 10 triá»‡u, báº¡n cÃ³ thá»ƒ vay tÃ­n cháº¥p vá»›i háº¡n má»©c khoáº£ng 50-100 triá»‡u tÃ¹y thuá»™c vÃ o Ä‘iá»ƒm tÃ­n dá»¥ng vÃ  Ä‘iá»u kiá»‡n cá»§a ngÃ¢n hÃ ng. LÃ£i suáº¥t thÆ°á»ng tá»« 15-25%/nÄƒm.\"\n",
    ")\n",
    "\n",
    "# Preview dataset\n",
    "builder.preview()\n",
    "\n",
    "# Xem thá»‘ng kÃª\n",
    "stats = builder.get_stats()\n",
    "print(\"\\nğŸ“Š Thá»‘ng kÃª:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. VÃ­ dá»¥ - Multi-turn Conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThÃªm multi-turn conversation\n",
    "builder.add_multi_turn_conversation([\n",
    "    {\n",
    "        \"user\": \"TÃ´i muá»‘n biáº¿t vá» sáº£n pháº©m tiáº¿t kiá»‡m\",\n",
    "        \"assistant\": \"ChÃºng tÃ´i cÃ³ nhiá»u sáº£n pháº©m tiáº¿t kiá»‡m vá»›i cÃ¡c ká»³ háº¡n khÃ¡c nhau. Báº¡n quan tÃ¢m Ä‘áº¿n ká»³ háº¡n nÃ o?\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Ká»³ háº¡n 6 thÃ¡ng\",\n",
    "        \"assistant\": \"Vá»›i ká»³ háº¡n 6 thÃ¡ng, lÃ£i suáº¥t hiá»‡n táº¡i lÃ  5.2%/nÄƒm. Sá»‘ tiá»n tá»‘i thiá»ƒu lÃ  1 triá»‡u Ä‘á»“ng. Báº¡n cÃ³ muá»‘n má»Ÿ tÃ i khoáº£n khÃ´ng?\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"CÃ³, tÃ´i muá»‘n má»Ÿ\",\n",
    "        \"assistant\": \"Äá»ƒ má»Ÿ tÃ i khoáº£n tiáº¿t kiá»‡m, báº¡n cáº§n Ä‘áº¿n chi nhÃ¡nh vá»›i CMND/CCCD vÃ  sá»‘ tiá»n gá»­i. Hoáº·c báº¡n cÃ³ thá»ƒ Ä‘Äƒng kÃ½ online qua á»©ng dá»¥ng ngÃ¢n hÃ ng.\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"âœ… ÄÃ£ thÃªm multi-turn conversation\")\n",
    "builder.preview(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load tá»« JSON File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o file JSON máº«u\n",
    "sample_data = [\n",
    "    {\n",
    "        \"question\": \"Tháº» tÃ­n dá»¥ng cÃ³ phÃ­ thÆ°á»ng niÃªn khÃ´ng?\",\n",
    "        \"answer\": \"CÃ³, tháº» tÃ­n dá»¥ng thÆ°á»ng cÃ³ phÃ­ thÆ°á»ng niÃªn tá»« 200.000 - 2.000.000 Ä‘á»“ng tÃ¹y loáº¡i tháº». Má»™t sá»‘ ngÃ¢n hÃ ng miá»…n phÃ­ nÄƒm Ä‘áº§u hoáº·c miá»…n phÃ­ náº¿u Ä‘áº¡t Ä‘iá»u kiá»‡n chi tiÃªu.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"LÃ m sao Ä‘á»ƒ tÄƒng háº¡n má»©c tháº» tÃ­n dá»¥ng?\",\n",
    "        \"answer\": \"Äá»ƒ tÄƒng háº¡n má»©c tháº» tÃ­n dá»¥ng, báº¡n cáº§n: 1) Sá»­ dá»¥ng tháº» thÆ°á»ng xuyÃªn vÃ  thanh toÃ¡n Ä‘Ãºng háº¡n, 2) CÃ³ thu nháº­p á»•n Ä‘á»‹nh, 3) ÄÄƒng kÃ½ tÄƒng háº¡n má»©c qua á»©ng dá»¥ng hoáº·c chi nhÃ¡nh. NgÃ¢n hÃ ng sáº½ xem xÃ©t vÃ  quyáº¿t Ä‘á»‹nh.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# LÆ°u vÃ o file táº¡m\n",
    "temp_json = \"/tmp/sample_data.json\"\n",
    "with open(temp_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(sample_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Load tá»« JSON\n",
    "builder2 = Qwen3DatasetBuilder(include_image=False)\n",
    "builder2.load_from_json(temp_json, format_type=\"qa\")\n",
    "\n",
    "print(f\"\\nâœ… ÄÃ£ load {len(builder2.dataset)} samples\")\n",
    "builder2.preview()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load tá»« CSV File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o file CSV máº«u\n",
    "sample_csv_data = {\n",
    "    \"question\": [\n",
    "        \"TÃ´i cÃ³ thá»ƒ chuyá»ƒn tiá»n online khÃ´ng?\",\n",
    "        \"PhÃ­ chuyá»ƒn tiá»n lÃ  bao nhiÃªu?\",\n",
    "        \"Thá»i gian chuyá»ƒn tiá»n trong nÆ°á»›c máº¥t bao lÃ¢u?\"\n",
    "    ],\n",
    "    \"answer\": [\n",
    "        \"CÃ³, báº¡n cÃ³ thá»ƒ chuyá»ƒn tiá»n online qua á»©ng dá»¥ng ngÃ¢n hÃ ng, internet banking hoáº·c ATM. Chá»‰ cáº§n cÃ³ tÃ i khoáº£n vÃ  Ä‘Ã£ Ä‘Äƒng kÃ½ dá»‹ch vá»¥.\",\n",
    "        \"PhÃ­ chuyá»ƒn tiá»n trong nÆ°á»›c thÆ°á»ng tá»« 5.000 - 11.000 Ä‘á»“ng/giao dá»‹ch tÃ¹y ngÃ¢n hÃ ng. Má»™t sá»‘ ngÃ¢n hÃ ng miá»…n phÃ­ má»™t sá»‘ giao dá»‹ch Ä‘áº§u tiÃªn trong thÃ¡ng.\",\n",
    "        \"Chuyá»ƒn tiá»n trong nÆ°á»›c thÆ°á»ng Ä‘Æ°á»£c xá»­ lÃ½ ngay láº­p tá»©c (real-time) hoáº·c trong vÃ²ng 1-2 giá» lÃ m viá»‡c tÃ¹y ngÃ¢n hÃ ng vÃ  thá»i Ä‘iá»ƒm giao dá»‹ch.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "temp_csv = \"/tmp/sample_data.csv\"\n",
    "pd.DataFrame(sample_csv_data).to_csv(temp_csv, index=False)\n",
    "\n",
    "# Load tá»« CSV\n",
    "builder3 = Qwen3DatasetBuilder(include_image=False)\n",
    "builder3.load_from_csv(temp_csv, question_col=\"question\", answer_col=\"answer\")\n",
    "\n",
    "print(f\"\\nâœ… ÄÃ£ load {len(builder3.dataset)} samples\")\n",
    "builder3.preview()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Validate vÃ  Export Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge táº¥t cáº£ datasets\n",
    "final_builder = Qwen3DatasetBuilder(include_image=False)\n",
    "\n",
    "# ThÃªm tá»« builder1, builder2, builder3\n",
    "for sample in builder.dataset:\n",
    "    final_builder.add_conversation(sample[\"messages\"])\n",
    "for sample in builder2.dataset:\n",
    "    final_builder.add_conversation(sample[\"messages\"])\n",
    "for sample in builder3.dataset:\n",
    "    final_builder.add_conversation(sample[\"messages\"])\n",
    "\n",
    "# Thá»‘ng kÃª cuá»‘i cÃ¹ng\n",
    "stats = final_builder.get_stats()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“Š THá»NG KÃŠ DATASET CUá»I CÃ™NG\")\n",
    "print(\"=\"*50)\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Preview\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PREVIEW DATASET\")\n",
    "print(\"=\"*50)\n",
    "final_builder.preview(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export ra JSON\n",
    "output_json = \"./qwen3_training_dataset.json\"\n",
    "final_builder.save_to_json(output_json)\n",
    "\n",
    "# Export ra JSONL (cho Hugging Face)\n",
    "output_jsonl = \"./qwen3_training_dataset.jsonl\"\n",
    "final_builder.save_to_jsonl(output_jsonl)\n",
    "\n",
    "# Convert sang Hugging Face Dataset\n",
    "hf_dataset = final_builder.to_huggingface_dataset()\n",
    "print(f\"\\nâœ… Hugging Face Dataset: {len(hf_dataset)} samples\")\n",
    "print(f\"   Features: {hf_dataset.features}\")\n",
    "\n",
    "# Chia train/test\n",
    "split_dataset = final_builder.split_train_test(test_ratio=0.2, shuffle=True, seed=42)\n",
    "print(f\"\\nâœ… Train set: {len(split_dataset['train'])} samples\")\n",
    "print(f\"âœ… Test set: {len(split_dataset['test'])} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Upload lÃªn Hugging Face (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment Ä‘á»ƒ upload dataset lÃªn Hugging Face\n",
    "# from huggingface_hub import login, HfApi\n",
    "# \n",
    "# # Login\n",
    "# login(token=\"YOUR_HF_TOKEN\")\n",
    "# \n",
    "# # Upload dataset\n",
    "# dataset_id = \"your-username/qwen3-bank-dataset\"\n",
    "# split_dataset.push_to_hub(dataset_id)\n",
    "# print(f\"âœ… ÄÃ£ upload dataset lÃªn {dataset_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. HÆ°á»›ng dáº«n sá»­ dá»¥ng\n",
    "\n",
    "### Format Dataset chuáº©n Qwen3:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng\"}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\", \n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"CÃ¢u tráº£ lá»i cá»§a AI\"}\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Format vá»›i Image (Qwen3VL):\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"image\", \"image\": \"path_or_url\"},\n",
    "        {\"type\": \"text\", \"text\": \"MÃ´ táº£ áº£nh nÃ y\"}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"MÃ´ táº£ vá» áº£nh...\"}\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### CÃ¡c cÃ¡ch táº¡o dataset:\n",
    "\n",
    "1. **Tá»« Q&A Ä‘Æ¡n giáº£n**: `builder.add_simple_qa(question, answer)`\n",
    "2. **Tá»« multi-turn conversation**: `builder.add_multi_turn_conversation(turns)`\n",
    "3. **Tá»« JSON file**: `builder.load_from_json(file_path)`\n",
    "4. **Tá»« CSV file**: `builder.load_from_csv(file_path)`\n",
    "5. **Tá»« conversation logs**: `builder.load_from_conversation_logs(file_path)`\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- âœ… Äáº£m báº£o má»—i conversation cÃ³ Ã­t nháº¥t user + assistant message\n",
    "- âœ… Validate format trÆ°á»›c khi thÃªm vÃ o dataset\n",
    "- âœ… Sá»­ dá»¥ng JSONL format cho dataset lá»›n (dá»… xá»­ lÃ½ tá»«ng dÃ²ng)\n",
    "- âœ… Chia train/test Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ model\n",
    "- âœ… Preview dataset trÆ°á»›c khi export\n",
    "\n",
    "### TÃ i liá»‡u tham kháº£o:\n",
    "\n",
    "Theo [Qwen Documentation](https://qwen.readthedocs.io/en/latest/):\n",
    "- Format messages pháº£i Ä‘Ãºng chuáº©n Qwen3\n",
    "- Há»— trá»£ cáº£ text-only vÃ  multimodal (text + image)\n",
    "- Dataset cÃ³ thá»ƒ upload lÃªn Hugging Face Ä‘á»ƒ chia sáº»\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
